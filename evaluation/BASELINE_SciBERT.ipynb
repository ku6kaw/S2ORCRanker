{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e33ac7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU is available. Device: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel # ★ AutoModelのみでOK\n",
    "import accelerate\n",
    "import sqlite3\n",
    "import faiss # ★ Faiss をインポート\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "# --- 1. GPUの確認 ---\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✅ GPU is available. Device: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"⚠️ GPU not found. Running on CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0a2da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer & PRE-TRAINED model from: allenai/scibert_scivocab_uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DOI map from data/processed/pretrained_doi_map.json...\n",
      "Loading Faiss index: data/processed/pretrained_scibert.faiss\n",
      "Faiss index loaded. Total vectors: 11,619,136\n"
     ]
    }
   ],
   "source": [
    "# --- 2. 設定とリソースのロード ---\n",
    "DB_PATH = \"data/processed/s2orc_filtered.db\"\n",
    "\n",
    "# ▼▼▼ 修正点: 事前学習済みモデルを使用 ▼▼▼\n",
    "MODEL_CHECKPOINT = \"allenai/scibert_scivocab_uncased\" \n",
    "\n",
    "# ▼▼▼ 修正点: 事前学習済みモデルのインデックスを使用 ▼▼▼\n",
    "FAISS_INDEX_FILE = \"data/processed/pretrained_scibert.faiss\"\n",
    "DOI_MAP_FILE = \"data/processed/pretrained_doi_map.json\"\n",
    "\n",
    "EVAL_PAPERS_FILE = \"data/datapapers/sampled/evaluation_data_papers_50_v2.csv\"\n",
    "TRAIN_FILE = \"data/processed/training_dataset_hard_negatives_1to3.csv\"\n",
    "\n",
    "RICH_RESULTS_FILE = \"data/processed/pretrained_scibert_evaluation_results.json\"\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "# 評価するkの値\n",
    "# ランキング上位の精度を見るための小さいk\n",
    "small_k_values = [1, 5, 10, 30, 50, 100, 200, 300, 500]\n",
    "# 網羅性を見るための大きいk (1000刻みで30000まで)\n",
    "large_k_values = list(range(1000, 30001, 1000))\n",
    "\n",
    "EVAL_K_VALUES = sorted(list(set(small_k_values + large_k_values)))\n",
    "\n",
    "# SAVE_TOP_K も評価の最大値に合わせる\n",
    "SAVE_TOP_K = 30000 \n",
    "\n",
    "print(f\"Loading tokenizer & PRE-TRAINED model from: {MODEL_CHECKPOINT}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "# ▼▼▼ 修正点: AutoModel (エンコーダーのみ) をロード ▼▼▼\n",
    "model = AutoModel.from_pretrained(MODEL_CHECKPOINT).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loading DOI map from {DOI_MAP_FILE}...\")\n",
    "with open(DOI_MAP_FILE, 'r') as f:\n",
    "    doi_to_index = json.load(f)\n",
    "id_to_doi = {v: k for k, v in doi_to_index.items()}\n",
    "\n",
    "# ▼▼▼ 修正点: Faissインデックスをロード ▼▼▼\n",
    "print(f\"Loading Faiss index: {FAISS_INDEX_FILE}\")\n",
    "index = faiss.read_index(FAISS_INDEX_FILE)\n",
    "total_vectors = index.ntotal\n",
    "print(f\"Faiss index loaded. Total vectors: {total_vectors:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81828b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing evaluation queries and ground truth...\n",
      "Loaded 2,338 training DOIs to exclude.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa0ec49200d4695a3a81bf4cc4b887f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building Ground Truth:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 50 valid evaluation queries.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. 評価データ（クエリと正解）の準備 ---\n",
    "print(\"Preparing evaluation queries and ground truth...\")\n",
    "\n",
    "# 1. 訓練データ（除外リスト）のDOIをロード\n",
    "df_train = pd.read_csv(TRAIN_FILE)\n",
    "df_train = df_train.dropna(subset=['abstract_a', 'abstract_b'])\n",
    "train_dois = set(df_train['abstract_a']) | set(df_train['abstract_b'])\n",
    "print(f\"Loaded {len(train_dois):,} training DOIs to exclude.\")\n",
    "\n",
    "# 2. 評価用データ論文（50件）のリストをロード\n",
    "df_eval_papers = pd.read_csv(EVAL_PAPERS_FILE)\n",
    "eval_data_paper_dois = tuple(df_eval_papers['cited_datapaper_doi'].unique())\n",
    "\n",
    "# 3. 「クエリ論文」と「正解DOIリスト」を作成\n",
    "evaluation_queries = [] \n",
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    for data_paper_doi in tqdm(eval_data_paper_dois, desc=\"Building Ground Truth\"):\n",
    "        query_gt = \"SELECT citing_doi FROM positive_candidates WHERE cited_datapaper_doi = ? AND human_annotation_status = 1\"\n",
    "        gt_rows = conn.execute(query_gt, (data_paper_doi,)).fetchall()\n",
    "        ground_truth_dois = {row[0] for row in gt_rows}\n",
    "        \n",
    "        if len(ground_truth_dois) >= 2:\n",
    "            query_doi = ground_truth_dois.pop()\n",
    "            query_text = conn.execute(\"SELECT abstract FROM papers WHERE doi = ?\", (query_doi,)).fetchone()\n",
    "            if query_text:\n",
    "                evaluation_queries.append({\n",
    "                    \"query_doi\": query_doi,\n",
    "                    \"query_abstract\": query_text[0],\n",
    "                    \"ground_truth_dois\": list(ground_truth_dois)\n",
    "                })\n",
    "\n",
    "print(f\"Prepared {len(evaluation_queries)} valid evaluation queries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732b9ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation... Scoring ALL 11,619,136 candidates using Faiss (CPU).\n",
      "Using CPU Faiss index (GPU index k limit is 2048).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d34f851ea44aec8f607484c8eadbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries (Total):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. 評価の実行 (事前学習モデル / Faiss L2距離) ---\n",
    "print(f\"Starting evaluation... Scoring ALL {total_vectors:,} candidates using Faiss (CPU).\")\n",
    "\n",
    "all_first_hit_ranks = [] \n",
    "all_recalls_at_k = {k: [] for k in EVAL_K_VALUES}\n",
    "all_rich_results = [] \n",
    "\n",
    "# ▼▼▼ 修正点: GPUインデックスの作成をコメントアウト ▼▼▼\n",
    "# res = faiss.StandardGpuResources()\n",
    "# gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "# print(\"Faiss index transferred to GPU.\")\n",
    "print(\"Using CPU Faiss index (GPU index k limit is 2048).\")\n",
    "# ▲▲▲ ------------------------------------------ ▲▲▲\n",
    "\n",
    "with torch.no_grad():\n",
    "    for query_data in tqdm(evaluation_queries, desc=\"Evaluating Queries (Total)\"):\n",
    "        \n",
    "        query_abstract = query_data[\"query_abstract\"]\n",
    "        ground_truth = set(query_data[\"ground_truth_dois\"])\n",
    "\n",
    "        # 1. クエリをベクトル化\n",
    "        inputs = tokenizer(query_abstract, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "        query_vector = outputs.pooler_output.cpu().numpy().astype(np.float32)\n",
    "\n",
    "        # --- 2. ★Faissで全DB（1160万件）を検索★ ---\n",
    "        k_to_search = max(max(EVAL_K_VALUES), SAVE_TOP_K)\n",
    "        \n",
    "        # ▼▼▼ 修正点: 'gpu_index' ではなく 'index' (CPU) を使用 ▼▼▼\n",
    "        distances, sorted_indices = index.search(query_vector, k_to_search)\n",
    "        \n",
    "        distances = distances[0]\n",
    "        sorted_indices = sorted_indices[0]\n",
    "        \n",
    "        # 3. 採点 と 4. リッチ結果の保存\n",
    "        first_hit_rank = 0 \n",
    "        hits_count = 0\n",
    "        hits_at_k = {k: 0 for k in EVAL_K_VALUES}\n",
    "        top_k_results_list = []\n",
    "        ranks_of_all_hits = []\n",
    "        current_rank = 1\n",
    "        \n",
    "        for i, idx in enumerate(sorted_indices):\n",
    "            if idx == -1: continue\n",
    "            if idx not in id_to_doi: continue\n",
    "            \n",
    "            doi = id_to_doi[idx]\n",
    "            if doi in train_dois: continue\n",
    "            \n",
    "            is_correct = (doi in ground_truth)\n",
    "            \n",
    "            if is_correct:\n",
    "                hits_count += 1\n",
    "                ranks_of_all_hits.append(current_rank)\n",
    "                if first_hit_rank == 0:\n",
    "                    first_hit_rank = current_rank\n",
    "            \n",
    "            for k in EVAL_K_VALUES:\n",
    "                if current_rank <= k and is_correct:\n",
    "                    hits_at_k[k] += 1\n",
    "            \n",
    "            top_k_results_list.append({\n",
    "                \"rank\": current_rank,\n",
    "                \"doi\": doi,\n",
    "                \"score\": float(distances[i]),\n",
    "                \"is_correct\": is_correct\n",
    "            })\n",
    "            \n",
    "            current_rank += 1 \n",
    "\n",
    "        # --- 5. 最終メトリクスの計算 ---\n",
    "        all_first_hit_ranks.append(first_hit_rank)\n",
    "            \n",
    "        for k in EVAL_K_VALUES:\n",
    "            recall = hits_at_k[k] / len(ground_truth) if ground_truth else 0\n",
    "            all_recalls_at_k[k].append(recall)\n",
    "            \n",
    "        all_rich_results.append({\n",
    "            \"query_doi\": query_data[\"query_doi\"],\n",
    "            \"total_ground_truth\": len(ground_truth),\n",
    "            \"ground_truth_dois\": list(ground_truth),\n",
    "            \"first_hit_rank\": first_hit_rank,\n",
    "            \"ranks_of_all_hits\": ranks_of_all_hits,\n",
    "            \"top_k_results\": top_k_results_list\n",
    "        })\n",
    "\n",
    "print(\"Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605ca9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving rich evaluation results to data/processed/pretrained_scibert_evaluation_results.json...\n",
      "Rich results saved.\n",
      "\n",
      "==================================================\n",
      "--- Final Evaluation Results: PRE-TRAINED SciBERT (Faiss L2 Distance) ---\n",
      "(Based on 50 queries, searching ALL 11,619,136 documents)\n",
      "==================================================\n",
      "MRR (Mean Reciprocal Rank): 0.0310\n",
      "Ranks of First Hit (0 = Not Found in Top 30000):\n",
      "[0, 37, 0, 0, 0, 0, 0, 0, 24224, 995, 0, 0, 0, 4, 0, 0, 0, 0, 14438, 0, 0, 0, 6871, 0, 0, 1847, 0, 0, 0, 0, 0, 5265, 0, 4713, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "--- Recall@K ---\n",
      "Recall@1   : 0.0000 (0.00%)\n",
      "Recall@5   : 0.0033 (0.33%)\n",
      "Recall@10  : 0.0033 (0.33%)\n",
      "Recall@30  : 0.0033 (0.33%)\n",
      "Recall@50  : 0.0041 (0.41%)\n",
      "Recall@100 : 0.0041 (0.41%)\n",
      "Recall@200 : 0.0041 (0.41%)\n",
      "Recall@300 : 0.0041 (0.41%)\n",
      "Recall@500 : 0.0041 (0.41%)\n",
      "Recall@1000: 0.0122 (1.22%)\n",
      "Recall@2000: 0.0180 (1.80%)\n",
      "Recall@3000: 0.0194 (1.94%)\n",
      "Recall@4000: 0.0194 (1.94%)\n",
      "Recall@5000: 0.0261 (2.61%)\n",
      "Recall@6000: 0.0328 (3.28%)\n",
      "Recall@7000: 0.0385 (3.85%)\n",
      "Recall@8000: 0.0385 (3.85%)\n",
      "Recall@9000: 0.0385 (3.85%)\n",
      "Recall@10000: 0.0385 (3.85%)\n",
      "Recall@11000: 0.0385 (3.85%)\n",
      "Recall@12000: 0.0385 (3.85%)\n",
      "Recall@13000: 0.0385 (3.85%)\n",
      "Recall@14000: 0.0385 (3.85%)\n",
      "Recall@15000: 0.0502 (5.02%)\n",
      "Recall@16000: 0.0502 (5.02%)\n",
      "Recall@17000: 0.0502 (5.02%)\n",
      "Recall@18000: 0.0502 (5.02%)\n",
      "Recall@19000: 0.0502 (5.02%)\n",
      "Recall@20000: 0.0502 (5.02%)\n",
      "Recall@21000: 0.0502 (5.02%)\n",
      "Recall@22000: 0.0502 (5.02%)\n",
      "Recall@23000: 0.0502 (5.02%)\n",
      "Recall@24000: 0.0502 (5.02%)\n",
      "Recall@25000: 0.0522 (5.22%)\n",
      "Recall@26000: 0.0522 (5.22%)\n",
      "Recall@27000: 0.0522 (5.22%)\n",
      "Recall@28000: 0.0522 (5.22%)\n",
      "Recall@29000: 0.0522 (5.22%)\n",
      "Recall@30000: 0.0522 (5.22%)\n",
      "==================================================\n",
      "Queries where first hit was NOT found (in Top 30000): 41 / 50\n"
     ]
    }
   ],
   "source": [
    "# --- 5. 最終結果の集計 ---\n",
    "\n",
    "# 5-1. 豊富な結果をJSONファイルに保存\n",
    "print(f\"Saving rich evaluation results to {RICH_RESULTS_FILE}...\")\n",
    "with open(RICH_RESULTS_FILE, 'w') as f:\n",
    "    json.dump(all_rich_results, f, indent=2)\n",
    "print(\"Rich results saved.\")\n",
    "\n",
    "# 5-2. 平均スコアのサマリーを表示\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"--- Final Evaluation Results: PRE-TRAINED SciBERT (Faiss L2 Distance) ---\")\n",
    "print(f\"(Based on {len(evaluation_queries)} queries, searching ALL {total_vectors:,} documents)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# MRR\n",
    "mrr_scores = [1.0 / r for r in all_first_hit_ranks if r > 0]\n",
    "mrr = np.mean(mrr_scores) if mrr_scores else 0.0\n",
    "print(f\"MRR (Mean Reciprocal Rank): {mrr:.4f}\")\n",
    "\n",
    "print(f\"Ranks of First Hit (0 = Not Found in Top {SAVE_TOP_K}):\")\n",
    "print(all_first_hit_ranks)\n",
    "\n",
    "print(\"\\n--- Recall@K ---\")\n",
    "for k in EVAL_K_VALUES:\n",
    "    recall_k = np.mean(all_recalls_at_k[k])\n",
    "    print(f\"Recall@{k:<4}: {recall_k:.4f} ({(recall_k * 100):.2f}%)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "not_found_count = len([r for r in all_first_hit_ranks if r == 0])\n",
    "print(f\"Queries where first hit was NOT found (in Top {SAVE_TOP_K}): {not_found_count} / {len(evaluation_queries)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
