{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7bd9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking Evaluation Ground Truth ---\n",
      "Loaded 50 data papers from data/datapapers/sampled/evaluation_data_papers_50.csv\n",
      "\n",
      "==================================================\n",
      "Found 2 data papers with ZERO 'Human: Used' (human_status=1) entries:\n",
      "               data_paper_doi  human_used_count\n",
      "15  10.1016/J.DIB.2016.05.025                 0\n",
      "33  10.1016/J.DIB.2018.11.111                 0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# --- 1. Ë®≠ÂÆö ---\n",
    "DB_PATH = \"data/processed/s2orc_filtered.db\"\n",
    "EVAL_PAPERS_FILE = \"data/datapapers/sampled/evaluation_data_papers_50.csv\"\n",
    "\n",
    "print(\"--- Checking Evaluation Ground Truth ---\")\n",
    "\n",
    "# --- 2. Ë©ï‰æ°Áî®„Éá„Éº„ÇøË´ñÊñáÔºà50‰ª∂Ôºâ„ÅÆ„É™„Çπ„Éà„Çí„É≠„Éº„Éâ ---\n",
    "try:\n",
    "    df_eval_papers = pd.read_csv(EVAL_PAPERS_FILE)\n",
    "    eval_data_paper_dois = tuple(df_eval_papers['cited_datapaper_doi'].unique())\n",
    "    print(f\"Loaded {len(eval_data_paper_dois)} data papers from {EVAL_PAPERS_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 3. DB„ÇíË™øÊüª ---\n",
    "results = []\n",
    "try:\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        for data_paper_doi in eval_data_paper_dois:\n",
    "            # Ê≠£Ëß£DOI (Human=1) „ÅÆÊï∞„Çí„Ç´„Ç¶„É≥„Éà\n",
    "            query_gt = \"SELECT COUNT(citing_doi) FROM positive_candidates WHERE cited_datapaper_doi = ? AND human_annotation_status = 1\"\n",
    "            count = conn.execute(query_gt, (data_paper_doi,)).fetchone()[0]\n",
    "            results.append({\n",
    "                'data_paper_doi': data_paper_doi,\n",
    "                'human_used_count': count\n",
    "            })\n",
    "\n",
    "    # --- 4. ÁµêÊûú„ÅÆË°®Á§∫ ---\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Ê≠£Ëß£„Åå0‰ª∂„ÅÆ„ÇÇ„ÅÆ„ÇíË°®Á§∫\n",
    "    df_missing = df_results[df_results['human_used_count'] == 0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    if not df_missing.empty:\n",
    "        print(f\"Found {len(df_missing)} data papers with ZERO 'Human: Used' (human_status=1) entries:\")\n",
    "        print(df_missing)\n",
    "    else:\n",
    "        print(\"All 50 evaluation data papers have at least 1 'Human: Used' entry.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b1d8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding Replacement Evaluation Papers (Top-K Cited) ---\n",
      "Total eligible pool size: 721\n",
      "Already used DOIs (Train + Eval): 200\n",
      "\n",
      "==================================================\n",
      "‚úÖ Found 2 replacement data papers (Top 2 by LLM 'Used' count):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cited_datapaper_doi</th>\n",
       "      <th>llm_used_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1002/ECY.2663</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>10.1038/S41597-019-0217-0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cited_datapaper_doi  llm_used_count\n",
       "0             10.1002/ECY.2663               3\n",
       "364  10.1038/S41597-019-0217-0               3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Appending these 2 papers to data/datapapers/sampled/evaluation_data_papers_50.csv...\n",
      "Successfully updated. New evaluation set size: 52 papers.\n",
      "\n",
      "--- ‚ùó Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó ‚ùó ---\n",
      "1. `evaluation_data_papers_50.csv` „Åå 52‰ª∂ „Å´Êõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü„ÄÇ\n",
      "2. `annotator_app` „Çí `ANNOTATION_MODE = \"evaluation\"` „Å´Ë®≠ÂÆö„Åó„Å¶Ëµ∑Âãï„Åó„ÄÅ\n",
      "   ‰ªäËøΩÂä†„Åï„Çå„Åü 2‰ª∂ „ÅÆË´ñÊñá„Å´Á¥ê„Å•„ÅèÂÄôË£ú„Çí**ÁõÆË¶ñ„Åß„Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥**„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
      "3. „Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥„ÅåÂÆå‰∫Ü„Åó„ÄÅÊñ∞„Åó„ÅÑ2‰ª∂„Å´ `human_status=1` „ÅÆÊ≠£Ëß£„Åå‰ΩúÊàê„Åï„Çå„Åü„Çâ„ÄÅ\n",
      "   Ë©ï‰æ°„Çπ„ÇØ„É™„Éó„Éà (`22b_...ipynb`) „ÇíÂÜçÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
      "   (‰ªäÂ∫¶„ÅØ 50‰ª∂‰∏≠50‰ª∂ „ÅåÂá¶ÁêÜ„Åï„Çå„Çã„ÅØ„Åö„Åß„Åô)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import numpy as np\n",
    "# ‚ñº‚ñº‚ñº tabulate„Åå‰∏çË¶Å„Å™ 'display' „Çí„Ç§„É≥„Éù„Éº„Éà ‚ñº‚ñº‚ñº\n",
    "from IPython.display import display\n",
    "\n",
    "# --- 1. Ë®≠ÂÆö ---\n",
    "DB_PATH = \"data/processed/s2orc_filtered.db\"\n",
    "EVAL_PAPERS_FILE = \"data/datapapers/sampled/evaluation_data_papers_50.csv\"\n",
    "TRAINING_PAPERS_FILE = \"data/datapapers/sampled/training_data_papers_50.csv\"\n",
    "\n",
    "N_REPLACEMENTS_NEEDED = 2 # 2‰ª∂‰∏çË∂≥„Åó„Å¶„ÅÑ„Çã\n",
    "\n",
    "print(\"--- Finding Replacement Evaluation Papers (Top-K Cited) ---\")\n",
    "\n",
    "try:\n",
    "    with sqlite3.connect(DB_PATH) as conn:\n",
    "        # 1. ÂÖÉ„ÅÆÊØçÈõÜÂõ£ÔºàLLM=Used„Åå2‰ª∂‰ª•‰∏äÔºâ„ÅÆÂÖ®„É™„Çπ„Éà„ÇíÂèñÂæó\n",
    "        query = \"\"\"\n",
    "            SELECT\n",
    "                cited_datapaper_doi,\n",
    "                COUNT(citing_doi) AS llm_used_count\n",
    "            FROM\n",
    "                positive_candidates\n",
    "            WHERE\n",
    "                llm_annotation_status = 1\n",
    "            GROUP BY\n",
    "                cited_datapaper_doi\n",
    "            HAVING\n",
    "                COUNT(citing_doi) >= 2;\n",
    "        \"\"\"\n",
    "        df_all_eligible = pd.read_sql_query(query, conn)\n",
    "        all_eligible_dois = set(df_all_eligible['cited_datapaper_doi'])\n",
    "        print(f\"Total eligible pool size: {len(all_eligible_dois)}\")\n",
    "\n",
    "    # 2. Êó¢„Å´‰ΩøÁî®Ê∏à„Åø„ÅÆDOI„Çí„É≠„Éº„Éâ\n",
    "    df_eval = pd.read_csv(EVAL_PAPERS_FILE)\n",
    "    eval_dois = set(df_eval['cited_datapaper_doi'])\n",
    "    \n",
    "    df_train = pd.read_csv(TRAINING_PAPERS_FILE)\n",
    "    train_dois = set(df_train['cited_datapaper_doi'])\n",
    "    \n",
    "    used_dois = eval_dois.union(train_dois)\n",
    "    print(f\"Already used DOIs (Train + Eval): {len(used_dois)}\")\n",
    "\n",
    "    # 3. Êú™‰ΩøÁî®„ÅÆDOI„Éó„Éº„É´„Çí‰ΩúÊàê\n",
    "    available_dois = list(all_eligible_dois - used_dois)\n",
    "    df_available = df_all_eligible[df_all_eligible['cited_datapaper_doi'].isin(available_dois)]\n",
    "    \n",
    "    if len(df_available) < N_REPLACEMENTS_NEEDED:\n",
    "        print(f\"‚ùå Error: Not enough available papers in the pool to find {N_REPLACEMENTS_NEEDED} replacements.\")\n",
    "    else:\n",
    "        # 4. Ë¢´ÂºïÁî®Êï∞Ôºàllm_used_countÔºâ„ÅåÂ§ö„ÅÑÈ†Ü„Å´„ÇΩ„Éº„Éà„Åó„ÄÅ‰∏ä‰Ωç2‰ª∂„ÇíÂèñÂæó\n",
    "        replacements_df = df_available.sort_values(by='llm_used_count', ascending=False).head(N_REPLACEMENTS_NEEDED)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"‚úÖ Found {N_REPLACEMENTS_NEEDED} replacement data papers (Top {N_REPLACEMENTS_NEEDED} by LLM 'Used' count):\")\n",
    "        \n",
    "        # ‚ñº‚ñº‚ñº ‰øÆÊ≠£ÁÇπ: .to_markdown() „Çí display() „Å´Â§âÊõ¥ ‚ñº‚ñº‚ñº\n",
    "        display(replacements_df)\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 5. ÂÖÉ„ÅÆCSV„Éï„Ç°„Ç§„É´„Å´ËøΩË®ò\n",
    "        print(f\"Appending these {N_REPLACEMENTS_NEEDED} papers to {EVAL_PAPERS_FILE}...\")\n",
    "        replacements_df.to_csv(EVAL_PAPERS_FILE, mode='a', header=False, index=False)\n",
    "        \n",
    "        df_new_eval = pd.read_csv(EVAL_PAPERS_FILE)\n",
    "        print(f\"Successfully updated. New evaluation set size: {len(df_new_eval)} papers.\")\n",
    "        \n",
    "        print(\"\\n--- ‚ùó Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó ‚ùó ---\")\n",
    "        print(\"1. `evaluation_data_papers_50.csv` „Åå 52‰ª∂ „Å´Êõ¥Êñ∞„Åï„Çå„Åæ„Åó„Åü„ÄÇ\")\n",
    "        print(\"2. `annotator_app` „Çí `ANNOTATION_MODE = \\\"evaluation\\\"` „Å´Ë®≠ÂÆö„Åó„Å¶Ëµ∑Âãï„Åó„ÄÅ\")\n",
    "        print(\"   ‰ªäËøΩÂä†„Åï„Çå„Åü 2‰ª∂ „ÅÆË´ñÊñá„Å´Á¥ê„Å•„ÅèÂÄôË£ú„Çí**ÁõÆË¶ñ„Åß„Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥**„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n",
    "        print(\"3. „Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥„ÅåÂÆå‰∫Ü„Åó„ÄÅÊñ∞„Åó„ÅÑ2‰ª∂„Å´ `human_status=1` „ÅÆÊ≠£Ëß£„Åå‰ΩúÊàê„Åï„Çå„Åü„Çâ„ÄÅ\")\n",
    "        print(\"   Ë©ï‰æ°„Çπ„ÇØ„É™„Éó„Éà (`22b_...ipynb`) „ÇíÂÜçÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n",
    "        print(\"   (‰ªäÂ∫¶„ÅØ 50‰ª∂‰∏≠50‰ª∂ „ÅåÂá¶ÁêÜ„Åï„Çå„Çã„ÅØ„Åö„Åß„Åô)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"üí• An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129439c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# --- 1. Ë®≠ÂÆö ---\n",
    "DB_PATH = \"data/processed/s2orc_filtered.db\"\n",
    "\n",
    "# ‚ñº‚ñº‚ñº „Å©„ÅÆ„É¢„Éº„Éâ„ÅÆ„Éá„Éº„Çø„Çí‰∏ÄÊã¨ÊâøË™ç„Åô„Çã„ÅãÈÅ∏Êäû ‚ñº‚ñº‚ñº\n",
    "# 'evaluation'     : Ë©ï‰æ°Áî®„Éá„Éº„ÇøÔºàÁ¥Ñ50„Ç∞„É´„Éº„ÉóÔºâ„ÅÆÊú™Âá¶ÁêÜÂàÜ\n",
    "# 'training'       : Ë®ìÁ∑¥Áî®„Éá„Éº„ÇøÔºà150„Ç∞„É´„Éº„ÉóÔºâ„ÅÆÊú™Âá¶ÁêÜÂàÜ\n",
    "# 'training_advanced': Ë®ìÁ∑¥Áî®„Éà„ÉÉ„Éó20„ÅÆÊú™Âá¶ÁêÜÂàÜ\n",
    "UPDATE_MODE = \"evaluation\" \n",
    "# ‚ñ≤‚ñ≤‚ñ≤ --------------------------------- ‚ñ≤‚ñ≤‚ñ≤\n",
    "\n",
    "# „Ç¢„Éé„ÉÜ„Éº„Ç∑„Éß„É≥ÂØæË±°„ÅÆDOI„É™„Çπ„Éà„ÇíË™≠„ÅøËæº„ÇÄ\n",
    "EVAL_PAPERS_FILE = \"data/datapapers/sampled/evaluation_data_papers_50.csv\"\n",
    "TRAINING_PAPERS_FILE = \"data/datapapers/sampled/training_data_papers_50.csv\"\n",
    "\n",
    "print(f\"Target mode set to: {UPDATE_MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da15b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. ÂØæË±°DOI„É™„Çπ„Éà„ÅÆË™≠„ÅøËæº„Åø ---\n",
    "TARGET_DOI_LIST = ()\n",
    "try:\n",
    "    if UPDATE_MODE == \"evaluation\":\n",
    "        df_papers = pd.read_csv(EVAL_PAPERS_FILE)\n",
    "        TARGET_DOI_LIST = tuple(df_papers['cited_datapaper_doi'].str.upper().tolist())\n",
    "    elif UPDATE_MODE == \"training\":\n",
    "        df_papers = pd.read_csv(TRAINING_PAPERS_FILE)\n",
    "        TARGET_DOI_LIST = tuple(df_papers['cited_datapaper_doi'].str.upper().tolist())\n",
    "    elif UPDATE_MODE == \"training_advanced\":\n",
    "        df_papers = pd.read_csv(TRAINING_PAPERS_FILE)\n",
    "        df_top_20 = df_papers.nlargest(20, 'used_paper_count')\n",
    "        TARGET_DOI_LIST = tuple(df_top_20['cited_datapaper_doi'].str.upper().tolist())\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown UPDATE_MODE: {UPDATE_MODE}\")\n",
    "        \n",
    "    print(f\"Loaded {len(TARGET_DOI_LIST)} data paper DOIs for mode '{UPDATE_MODE}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading DOI lists: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b858d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. „Éá„Éº„Çø„Éô„Éº„Çπ„ÅÆ‰∏ÄÊã¨Êõ¥Êñ∞ ---\n",
    "if TARGET_DOI_LIST:\n",
    "    print(\"Connecting to database...\")\n",
    "    try:\n",
    "        with sqlite3.connect(DB_PATH) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # 1. Êõ¥Êñ∞ÂØæË±°„ÅÆ‰ª∂Êï∞„Çí‰∫ãÂâç„Å´„Ç´„Ç¶„É≥„Éà\n",
    "            placeholders = ','.join('?' for _ in TARGET_DOI_LIST)\n",
    "            count_query = f\"\"\"\n",
    "                SELECT COUNT(*)\n",
    "                FROM positive_candidates\n",
    "                WHERE cited_datapaper_doi IN ({placeholders})\n",
    "                  AND llm_annotation_status = 1\n",
    "                  AND human_annotation_status = 0\n",
    "            \"\"\"\n",
    "            # (TARGET_DOI_LIST„Çí2ÂõûÊ∏°„ÅôÂøÖË¶Å„Åå„ÅÇ„Çã„Åü„ÇÅ„ÄÅ„É™„Çπ„Éà„ÇíÁµêÂêà)\n",
    "            params = TARGET_DOI_LIST\n",
    "            count_before = cursor.execute(count_query, params).fetchone()[0]\n",
    "            \n",
    "            if count_before == 0:\n",
    "                print(\"No unprocessed items found. Database is already up to date.\")\n",
    "            else:\n",
    "                print(f\"Found {count_before:,} items to approve (set human_status=1)...\")\n",
    "                \n",
    "                # 2. ‰∏ÄÊã¨Êõ¥Êñ∞ÔºàUPDATEÔºâ„ÅÆÂÆüË°å\n",
    "                update_query = f\"\"\"\n",
    "                    UPDATE positive_candidates\n",
    "                    SET human_annotation_status = 1\n",
    "                    WHERE cited_datapaper_doi IN ({placeholders})\n",
    "                      AND llm_annotation_status = 1\n",
    "                      AND human_annotation_status = 0\n",
    "                \"\"\"\n",
    "                \n",
    "                cursor.execute(update_query, params)\n",
    "                updated_rows = cursor.rowcount # ÂÆüÈöõ„Å´Êõ¥Êñ∞„Åï„Çå„ÅüË°åÊï∞\n",
    "                conn.commit()\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(f\"‚úÖ Successfully updated {updated_rows:,} rows.\")\n",
    "                print(f\"Mode '{UPDATE_MODE}' is now fully annotated.\")\n",
    "                print(\"=\"*50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üí• An error occurred during database update: {e}\")\n",
    "else:\n",
    "    print(\"No target DOIs loaded. Script stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
