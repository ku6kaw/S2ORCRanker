{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40961e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking Manual Annotation Progress for Evaluation Set ---\n",
      "\n",
      "==================================================\n",
      "--- Overall Progress Summary ---\n",
      "è©•ä¾¡å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿è«–æ–‡æ•°: 100\n",
      "ç›®è¦–ç¢ºèªå¯¾è±¡ã®å€™è£œè«–æ–‡ç·æ•° (LLMãŒ'Used'ã¨åˆ¤å®š): 587\n",
      "--------------------------------------------------\n",
      "ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†æ•°: 2\n",
      "é€²æ—ç‡: 0.34%\n",
      "==================================================\n",
      "\n",
      "--- Progress by Data Paper ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# --- Step 1: è¨­å®š ---\n",
    "DB_PATH = \"../data/processed/s2orc_filtered.db\"\n",
    "EVALUATION_DATAPAPERS_FILE = \"../data/datapapers/sampled/evaluation_data_papers.csv\"\n",
    "\n",
    "def check_evaluation_progress():\n",
    "    \"\"\"\n",
    "    è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç›®è¦–ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®é€²æ—çŠ¶æ³ã‚’ç¢ºèªã—ã€\n",
    "    ã‚µãƒãƒªãƒ¼ã¨è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤ºã™ã‚‹ã€‚\n",
    "    \"\"\"\n",
    "    print(\"--- Checking Manual Annotation Progress for Evaluation Set ---\")\n",
    "\n",
    "    if not os.path.exists(DB_PATH) or not os.path.exists(EVALUATION_DATAPAPERS_FILE):\n",
    "        print(f\"âŒ Error: Database or evaluation data paper file not found.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        with sqlite3.connect(DB_PATH) as conn:\n",
    "            # --- 1. è©•ä¾¡ç”¨ã®ãƒ‡ãƒ¼ã‚¿è«–æ–‡ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿ ---\n",
    "            df_eval_papers = pd.read_csv(EVALUATION_DATAPAPERS_FILE)\n",
    "            eval_datapaper_dois = tuple(df_eval_papers['cited_datapaper_doi'].unique())\n",
    "            \n",
    "            # --- 2. è©•ä¾¡å¯¾è±¡ã®å…¨ä½“åƒã‚’å–å¾— ---\n",
    "            placeholders = ','.join('?' for _ in eval_datapaper_dois)\n",
    "            \n",
    "            query_total = f\"\"\"\n",
    "                SELECT COUNT(*) FROM positive_candidates\n",
    "                WHERE cited_datapaper_doi IN ({placeholders}) AND llm_annotation_status = 1\n",
    "            \"\"\"\n",
    "            total_to_annotate = conn.execute(query_total, eval_datapaper_dois).fetchone()[0]\n",
    "\n",
    "            query_annotated = f\"\"\"\n",
    "                SELECT COUNT(*) FROM positive_candidates\n",
    "                WHERE cited_datapaper_doi IN ({placeholders}) AND llm_annotation_status = 1 AND human_annotation_status != 0\n",
    "            \"\"\"\n",
    "            total_annotated = conn.execute(query_annotated, eval_datapaper_dois).fetchone()[0]\n",
    "\n",
    "            # --- 3. å…¨ä½“é€²æ—ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º ---\n",
    "            progress_percent = (total_annotated / total_to_annotate * 100) if total_to_annotate > 0 else 0\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"--- Overall Progress Summary ---\")\n",
    "            print(f\"è©•ä¾¡å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿è«–æ–‡æ•°: {len(eval_datapaper_dois):,}\")\n",
    "            print(f\"ç›®è¦–ç¢ºèªå¯¾è±¡ã®å€™è£œè«–æ–‡ç·æ•° (LLMãŒ'Used'ã¨åˆ¤å®š): {total_to_annotate:,}\")\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†æ•°: {total_annotated:,}\")\n",
    "            print(f\"é€²æ—ç‡: {progress_percent:.2f}%\")\n",
    "            print(\"=\"*50)\n",
    "\n",
    "            # --- 4. ãƒ‡ãƒ¼ã‚¿è«–æ–‡ã”ã¨ã®è©³ç´°ãªé€²æ—ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º ---\n",
    "            print(\"\\n--- Progress by Data Paper ---\")\n",
    "            \n",
    "            query_details = f\"\"\"\n",
    "                SELECT\n",
    "                    cited_datapaper_doi,\n",
    "                    COUNT(citing_doi) AS total_candidates,\n",
    "                    SUM(CASE WHEN human_annotation_status != 0 THEN 1 ELSE 0 END) AS annotated_count\n",
    "                FROM\n",
    "                    positive_candidates\n",
    "                WHERE\n",
    "                    cited_datapaper_doi IN ({placeholders}) AND llm_annotation_status = 1\n",
    "                GROUP BY\n",
    "                    cited_datapaper_doi\n",
    "            \"\"\"\n",
    "            df_details = pd.read_sql_query(query_details, conn, params=eval_datapaper_dois)\n",
    "            \n",
    "            df_details['progress_%'] = (df_details['annotated_count'] / df_details['total_candidates'] * 100).fillna(0)\n",
    "            \n",
    "            # â–¼â–¼â–¼ ä¿®æ­£ç‚¹: `papers`ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«æƒ…å ±ã‚’å–å¾— â–¼â–¼â–¼\n",
    "            df_papers_info = pd.read_sql_query(\"SELECT doi, title FROM papers\", conn)\n",
    "            df_final_details = pd.merge(\n",
    "                df_details, \n",
    "                df_papers_info, \n",
    "                left_on='cited_datapaper_doi',\n",
    "                right_on='doi',\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            df_final_details = df_final_details[['title', 'annotated_count', 'total_candidates', 'progress_%']]\n",
    "            df_final_details['progress_%'] = df_final_details['progress_%'].map('{:.1f}%'.format)\n",
    "            \n",
    "            display(df_final_details.sort_values(by='annotated_count', ascending=True))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ’¥ An error occurred: {e}\")\n",
    "\n",
    "# --- å®Ÿè¡Œ ---\n",
    "check_evaluation_progress()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
