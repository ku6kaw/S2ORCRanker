{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a02021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Rebuilding Evaluation Set to Target Size ---\n",
      "Input file: data/datapapers/sampled/evaluation_data_papers_50.csv\n",
      "Output file: data/datapapers/sampled/evaluation_data_papers_50_v2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# --- 1. è¨­å®š ---\n",
    "DB_PATH = \"data/processed/s2orc_filtered.db\"\n",
    "# èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "BASE_EVAL_PAPERS_FILE = \"data/datapapers/sampled/evaluation_data_papers_50.csv\"\n",
    "TRAINING_PAPERS_FILE = \"data/datapapers/sampled/training_data_papers_50.csv\"\n",
    "\n",
    "# â–¼â–¼â–¼ ä¿®æ­£ç‚¹: æ–°ã—ã„å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å â–¼â–¼â–¼\n",
    "FINAL_EVAL_PAPERS_FILE = \"data/datapapers/sampled/evaluation_data_papers_50_v2.csv\"\n",
    "\n",
    "TARGET_EVAL_SIZE = 50 # æœ€çµ‚çš„ãªç›®æ¨™ä»¶æ•°\n",
    "\n",
    "print(\"--- Rebuilding Evaluation Set to Target Size ---\")\n",
    "print(f\"Input file: {BASE_EVAL_PAPERS_FILE}\")\n",
    "print(f\"Output file: {FINAL_EVAL_PAPERS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c844f4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading current evaluation set: data/datapapers/sampled/evaluation_data_papers_50.csv\n",
      "Current file has 50 entries.\n",
      "\n",
      "Found 46 valid papers (Human Used >= 2).\n",
      "Found 4 invalid papers (Human Used < 2) to be removed:\n",
      "['10.5194/ESSD-14-1917-2022', '10.1111/GEB.13179', '10.1038/S41597-019-0288-Y', '10.1016/J.DIB.2019.104313']\n"
     ]
    }
   ],
   "source": [
    "# --- ã‚¹ãƒ†ãƒƒãƒ—1: ç¾çŠ¶ã®è©•ä¾¡ã‚»ãƒƒãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ---\n",
    "print(f\"\\nLoading current evaluation set: {BASE_EVAL_PAPERS_FILE}\")\n",
    "try:\n",
    "    df_eval_current = pd.read_csv(BASE_EVAL_PAPERS_FILE)\n",
    "    current_eval_dois = tuple(df_eval_current['cited_datapaper_doi'].unique())\n",
    "    print(f\"Current file has {len(df_eval_current)} entries.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "    raise\n",
    "\n",
    "# DBã«æŽ¥ç¶šã—ã€ãƒšã‚¢ä½œæˆå¯èƒ½ï¼ˆHuman: Used >= 2ï¼‰ãªDOIã‚’ç‰¹å®š\n",
    "valid_eval_dois = []\n",
    "invalid_eval_dois = []\n",
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    for doi in current_eval_dois:\n",
    "        # è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ(22b)ã®ã‚»ãƒ«4ã®ãƒ­ã‚¸ãƒƒã‚¯ã¨åˆã‚ã›ã‚‹\n",
    "        query_gt = \"SELECT COUNT(citing_doi) FROM positive_candidates WHERE cited_datapaper_doi = ? AND human_annotation_status = 1\"\n",
    "        count = conn.execute(query_gt, (doi,)).fetchone()[0]\n",
    "        \n",
    "        if count >= 2: # æ­£è§£ãŒ2ä»¶ä»¥ä¸Šï¼ˆã‚¯ã‚¨ãƒª1ä»¶ + æ­£è§£1ä»¶ä»¥ä¸Šï¼‰ã‚ã‚‹ã‚‚ã®\n",
    "            valid_eval_dois.append(doi)\n",
    "        else:\n",
    "            invalid_eval_dois.append(doi)\n",
    "\n",
    "print(f\"\\nFound {len(valid_eval_dois)} valid papers (Human Used >= 2).\")\n",
    "print(f\"Found {len(invalid_eval_dois)} invalid papers (Human Used < 2) to be removed:\")\n",
    "print(invalid_eval_dois)\n",
    "\n",
    "# æœ‰åŠ¹ãªè«–æ–‡ï¼ˆ46ä»¶ã®ã¯ãšï¼‰ã®DataFrameã‚’ä½œæˆ\n",
    "df_eval_valid = df_eval_current[df_eval_current['cited_datapaper_doi'].isin(valid_eval_dois)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495e2367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Need to add 4 new data papers.\n",
      "Total DOIs already in use (Train + Valid Eval): 196\n",
      "Available pool size (unused papers): 525\n",
      "\n",
      "==================================================\n",
      "âœ… Selected 4 new data papers (Top 4 by LLM 'Used' count):\n",
      "| cited_datapaper_doi       |   llm_used_count |\n",
      "|:--------------------------|-----------------:|\n",
      "| 10.5194/ESSD-14-1917-2022 |               25 |\n",
      "| 10.1016/J.DIB.2016.05.025 |                8 |\n",
      "| 10.1016/J.DIB.2018.11.111 |                5 |\n",
      "| 10.1038/S41597-019-0288-Y |                4 |\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- ã‚¹ãƒ†ãƒƒãƒ—2: ä¸è¶³åˆ†ã®å€™è£œã‚’é¸å®š ---\n",
    "\n",
    "# â–¼â–¼â–¼ ä¿®æ­£ç‚¹1: tabulateã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« â–¼â–¼â–¼\n",
    "%pip install tabulate\n",
    "\n",
    "n_needed = TARGET_EVAL_SIZE - len(df_eval_valid)\n",
    "\n",
    "if n_needed <= 0:\n",
    "    print(f\"\\nEvaluation set already has {len(df_eval_valid)} valid papers. No additions needed.\")\n",
    "    df_final_eval_set = df_eval_valid\n",
    "else:\n",
    "    print(f\"\\nNeed to add {n_needed} new data papers.\")\n",
    "    \n",
    "    df_train = pd.read_csv(TRAINING_PAPERS_FILE)\n",
    "    train_dois = set(df_train['cited_datapaper_doi'])\n",
    "    used_dois = set(valid_eval_dois).union(train_dois)\n",
    "    print(f\"Total DOIs already in use (Train + Valid Eval): {len(used_dois)}\")\n",
    "\n",
    "    try:\n",
    "        with sqlite3.connect(DB_PATH) as conn:\n",
    "            query = \"\"\"\n",
    "                SELECT\n",
    "                    cited_datapaper_doi,\n",
    "                    COUNT(citing_doi) AS llm_used_count\n",
    "                FROM\n",
    "                    positive_candidates\n",
    "                WHERE\n",
    "                    llm_annotation_status = 1\n",
    "                GROUP BY\n",
    "                    cited_datapaper_doi\n",
    "                HAVING\n",
    "                    COUNT(citing_doi) >= 2;\n",
    "            \"\"\"\n",
    "            df_all_eligible = pd.read_sql_query(query, conn)\n",
    "            \n",
    "            df_available = df_all_eligible[~df_all_eligible['cited_datapaper_doi'].isin(used_dois)]\n",
    "            print(f\"Available pool size (unused papers): {len(df_available)}\")\n",
    "            \n",
    "            if len(df_available) < n_needed:\n",
    "                print(f\"âŒ Error: Not enough available papers in the pool ({len(df_available)}) to find {n_needed} replacements.\")\n",
    "            else:\n",
    "                df_replacements = df_available.sort_values(by='llm_used_count', ascending=False).head(n_needed)\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(f\"âœ… Selected {n_needed} new data papers (Top {n_needed} by LLM 'Used' count):\")\n",
    "                \n",
    "                # â–¼â–¼â–¼ ä¿®æ­£ç‚¹2: è¡¨ç¤ºã‚¨ãƒ©ãƒ¼ã‚’æ¡ã‚Šã¤ã¶ã™ â–¼â–¼â–¼\n",
    "                try:\n",
    "                    print(df_replacements.to_markdown(index=False))\n",
    "                except ImportError:\n",
    "                    print(\"(Could not print markdown, showing simple list):\")\n",
    "                    print(df_replacements)\n",
    "                # â–²â–²â–² --------------------------------- â–²â–²â–²\n",
    "                    \n",
    "                print(\"=\"*50)\n",
    "                \n",
    "                df_final_eval_set = pd.concat([df_eval_valid, df_replacements], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ’¥ An error occurred during selection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a839b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updating DB for 4 new papers...\n",
      "Setting 'human_annotation_status = 1' for all 'llm_annotation_status = 1' candidates...\n",
      "Found 0 candidate rows to mark as 'Human: Used'.\n",
      "âœ… DB Update Complete. 0 rows affected.\n",
      "\n",
      "Saving final evaluation set with 50 papers to NEW FILE: data/datapapers/sampled/evaluation_data_papers_50_v2.csv...\n",
      "âœ… New CSV file created successfully.\n",
      "\n",
      "--- Process Complete ---\n",
      "å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ« 'data/datapapers/sampled/evaluation_data_papers_50.csv' ã¯å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n",
      "ä»Šå¾Œã®è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯ã€'data/datapapers/sampled/evaluation_data_papers_50_v2.csv' ã‚’å‚ç…§ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚\n"
     ]
    }
   ],
   "source": [
    "# --- ã‚¹ãƒ†ãƒƒãƒ—3: DBã®ä¸€æ‹¬æ›´æ–°ã¨CSVã®ã€Œæ–°è¦ã€ä¿å­˜ ---\n",
    "if 'df_replacements' in locals() and not df_replacements.empty:\n",
    "    \n",
    "    new_dois_to_update = tuple(df_replacements['cited_datapaper_doi'].unique())\n",
    "    \n",
    "    print(f\"\\nUpdating DB for {len(new_dois_to_update)} new papers...\")\n",
    "    print(\"Setting 'human_annotation_status = 1' for all 'llm_annotation_status = 1' candidates...\")\n",
    "    \n",
    "    try:\n",
    "        with sqlite3.connect(DB_PATH) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # 1. æ›´æ–°å¯¾è±¡ã®ä»¶æ•°ã‚’äº‹å‰ã«ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "            placeholders = ','.join('?' for _ in new_dois_to_update)\n",
    "            count_query = f\"\"\"\n",
    "                SELECT COUNT(*)\n",
    "                FROM positive_candidates\n",
    "                WHERE cited_datapaper_doi IN ({placeholders})\n",
    "                  AND llm_annotation_status = 1\n",
    "                  AND human_annotation_status = 0\n",
    "            \"\"\"\n",
    "            count_before = cursor.execute(count_query, new_dois_to_update).fetchone()[0]\n",
    "            print(f\"Found {count_before:,} candidate rows to mark as 'Human: Used'.\")\n",
    "            \n",
    "            # 2. ä¸€æ‹¬æ›´æ–°ï¼ˆUPDATEï¼‰ã®å®Ÿè¡Œ\n",
    "            update_query = f\"\"\"\n",
    "                UPDATE positive_candidates\n",
    "                SET human_annotation_status = 1\n",
    "                WHERE cited_datapaper_doi IN ({placeholders})\n",
    "                  AND llm_annotation_status = 1\n",
    "                  AND human_annotation_status = 0\n",
    "            \"\"\"\n",
    "            cursor.execute(update_query, new_dois_to_update)\n",
    "            updated_rows = cursor.rowcount\n",
    "            conn.commit()\n",
    "            print(f\"âœ… DB Update Complete. {updated_rows:,} rows affected.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ’¥ An error occurred during DB update: {e}\")\n",
    "\n",
    "# --- â–¼â–¼â–¼ ä¿®æ­£ç‚¹: ã€Œä¸Šæ›¸ãã€ã§ã¯ãªãã€Œæ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã€ã«ä¿å­˜ ---\n",
    "if 'df_final_eval_set' in locals():\n",
    "    print(f\"\\nSaving final evaluation set with {len(df_final_eval_set)} papers to NEW FILE: {FINAL_EVAL_PAPERS_FILE}...\")\n",
    "    # å…ƒã®CSVã‚’ä¸Šæ›¸ãã›ãšã€æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åã§ä¿å­˜\n",
    "    df_final_eval_set.to_csv(FINAL_EVAL_PAPERS_FILE, index=False)\n",
    "    print(\"âœ… New CSV file created successfully.\")\n",
    "    print(\"\\n--- Process Complete ---\")\n",
    "    print(f\"å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ« '{BASE_EVAL_PAPERS_FILE}' ã¯å¤‰æ›´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\")\n",
    "    print(f\"ä»Šå¾Œã®è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯ã€'{FINAL_EVAL_PAPERS_FILE}' ã‚’å‚ç…§ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚\")\n",
    "else:\n",
    "    print(\"No changes made.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
