# configs/evaluate.yaml

defaults:
  - _self_

debug: false

seed: 42

logging:
  use_wandb: true
  project_name: "s2orc-ranker"
  run_name: "eval_retriever_bi_encoder_50q"
  tags: ["evaluation", "retriever", "bi-encoder"]

# データ設定
data:
  # 全文(Abstract)が格納されているSQLite DB
  db_path: "data/processed/s2orc_filtered.db"
  
  # 評価用データセット（クエリと正解ペア）
  eval_jsonl_file: "data/processed/evaluation_dataset_rich.jsonl"
  
  # ベクトル保存先ディレクトリ
  output_dir: "data/processed/embeddings"
  
  # 保存ファイル名
  embeddings_file: "corpus_embeddings.npy"
  doi_map_file: "corpus_doi_map.json"

# モデル設定
model:
  # 学習済みモデルのパス（run_train.pyの出力先を指定）
  # 例: models/output_model/best_model
  path: "models/output_model/best_model"
  
  # ベースモデル名（トークナイザ読み込み用）
  base_name: "allenai/scibert_scivocab_uncased"
  max_length: 512
  
  # 推論時のバッチサイズ (VRAMに合わせて調整: A6000なら大きくできる)
  batch_size: 256 # A6000なら512~1024でもいけるかも

# 評価設定
evaluation:
  # Recall@K の Kリスト
  k_values: [1, 5, 10, 50, 100, 300, 500, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000, 26000, 27000, 28000, 29000, 30000, 31000, 32000, 33000, 34000, 35000, 36000, 37000, 38000, 39000, 40000, 41000, 42000, 43000, 44000, 45000, 46000, 47000, 48000, 49000, 50000, 51000, 52000, 53000, 54000, 55000, 56000, 57000, 58000, 59000, 60000, 61000, 62000, 63000, 64000, 65000, 66000, 67000, 68000, 69000, 70000, 71000, 72000, 73000, 74000, 75000, 76000, 77000, 78000, 79000, 80000, 81000, 82000, 83000, 84000, 85000, 86000, 87000, 88000, 89000, 90000, 91000, 92000, 93000, 94000, 95000, 96000, 97000, 98000, 99000, 100000]
  
  # 結果の保存先
  result_file: "evaluation_results_50q_100k.json"

  use_faiss: true
  gpu_search: false

  save_candidates: true
  candidates_file: "candidates_for_reranking_50q_100k.json"
  candidates_k: 100000
  calc_full_rank: true
  queries_per_dataset: 1