Loading DOI map from data/processed/embeddings/SPECTER2_HardNeg/corpus_doi_map.json...
Loading embeddings (mmap) from data/processed/embeddings/SPECTER2_HardNeg/corpus_embeddings.npy...
Building Faiss Index for candidate retrieval...
Indexing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233/233 [00:31<00:00,  7.34it/s]
Loading query encoder: models/checkpoints/bi_encoder/Bi_SPECTER2_MNRL_HardNeg/best_model
Some weights of the model checkpoint at models/checkpoints/bi_encoder/Bi_SPECTER2_MNRL_HardNeg/best_model were not used when initializing SiameseBiEncoder: ['bert.encoder.layer.0.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.0.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.0.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.0.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.1.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.1.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.1.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.1.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.10.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.10.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.10.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.10.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.11.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.11.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.11.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.11.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.2.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.2.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.2.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.2.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.3.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.3.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.3.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.3.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.4.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.4.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.4.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.4.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.5.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.5.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.5.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.5.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.6.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.6.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.6.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.6.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.7.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.7.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.7.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.7.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.8.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.8.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.8.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.8.output.adapters.[PRX].adapter_up.weight', 'bert.encoder.layer.9.output.adapters.[PRX].adapter_down.0.bias', 'bert.encoder.layer.9.output.adapters.[PRX].adapter_down.0.weight', 'bert.encoder.layer.9.output.adapters.[PRX].adapter_up.bias', 'bert.encoder.layer.9.output.adapters.[PRX].adapter_up.weight']
- This IS expected if you are initializing SiameseBiEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing SiameseBiEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of SiameseBiEncoder were not initialized from the model checkpoint at models/checkpoints/bi_encoder/Bi_SPECTER2_MNRL_HardNeg/best_model and are newly initialized: ['classifier_head.0.bias', 'classifier_head.0.weight', 'classifier_head.2.bias', 'classifier_head.2.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
ðŸ”„ Loading Adapter config: allenai/specter2
   Attempting to load adapter from checkpoint: models/checkpoints/bi_encoder/Bi_SPECTER2_MNRL_HardNeg/best_model
   Checkpoint load failed (No file pytorch_adapter.bin or no file adapter_config.json found in directory models/checkpoints/bi_encoder/Bi_SPECTER2_MNRL_HardNeg/best_model), falling back to Hub: allenai/specter2
[2025-11-29 08:02:55,479][adapters.utils][INFO] - Attempting to load adapter from HF Model Hub...
Fetching 4 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 2312.50it/s]
[2025-11-29 08:02:55,722][adapters.loading][INFO] - Loading module configuration from /home/kurokawa/.cache/huggingface/hub/models--allenai--specter2/snapshots/2081559630a80fc5851d8f798a05ba81e9468089/adapter_config.json
[2025-11-29 08:02:55,724][adapters.configuration.model_adapters_config][INFO] - Adding adapter '[PRX]'.
[2025-11-29 08:02:55,746][adapters.model_mixin][WARNING] - There are adapters available but none are activated for the forward pass.
[2025-11-29 08:02:55,757][adapters.loading][INFO] - Loading module weights from /home/kurokawa/.cache/huggingface/hub/models--allenai--specter2/snapshots/2081559630a80fc5851d8f798a05ba81e9468089/pytorch_adapter.bin
âœ… Adapter '[PRX]' activated.
Loading queries from data/processed/evaluation_dataset_rich.jsonl...
Sampling 1 query(s) per dataset...
Reduced queries from 312 to 50.
Loaded 50 queries for evaluation.
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:15<00:00, 14.72s/it]

=== Evaluation Results (Retriever) ===
MRR: 0.0106
Recall@1: 0.0000
Recall@5: 0.0200
Recall@10: 0.0200
Recall@50: 0.0200
Recall@100: 0.0200
Recall@300: 0.0800
Recall@500: 0.1000
Recall@1000: 0.1200
Recall@2000: 0.1600
Recall@3000: 0.1600
Recall@4000: 0.2600
Recall@5000: 0.2600
Recall@6000: 0.3000
Recall@7000: 0.3000
Recall@8000: 0.3400
Recall@9000: 0.3400
Recall@10000: 0.3600
Recall@11000: 0.3800
Recall@12000: 0.4200
Recall@13000: 0.4600
Recall@14000: 0.4600
Recall@15000: 0.4800
Recall@16000: 0.5000
Recall@17000: 0.5200
Recall@18000: 0.5200
Recall@19000: 0.5600
Recall@20000: 0.5600
Recall@21000: 0.5600
Recall@22000: 0.5800
Recall@23000: 0.5800
Recall@24000: 0.5800
Recall@25000: 0.5800
Recall@26000: 0.5800
Recall@27000: 0.5800
Recall@28000: 0.5800
Recall@29000: 0.6000
Recall@30000: 0.6200
Recall@31000: 0.6200
Recall@32000: 0.6200
Recall@33000: 0.6200
Recall@34000: 0.6200
Recall@35000: 0.6200
Recall@36000: 0.6200
Recall@37000: 0.6200
Recall@38000: 0.6200
Recall@39000: 0.6200
Recall@40000: 0.6200
Recall@41000: 0.6200
Recall@42000: 0.6200
Recall@43000: 0.6200
Recall@44000: 0.6200
Recall@45000: 0.6200
Recall@46000: 0.6200
Recall@47000: 0.6200
Recall@48000: 0.6200
Recall@49000: 0.6200
Recall@50000: 0.6200
