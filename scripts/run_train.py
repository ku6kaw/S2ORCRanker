# scripts/run_train.py

import sys
import os
import hydra
from omegaconf import DictConfig, OmegaConf
import torch
from transformers import AutoTokenizer, TrainingArguments, AutoConfig, EarlyStoppingCallback
from torch.optim import AdamW
import wandb
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import adapters

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.getcwd())

from src.modeling.bi_encoder import SiameseBiEncoder
from src.modeling.cross_encoder import CrossEncoderMarginModel
from src.training.dataset import TextRankingDataset, CrossEncoderTripletCollator # â˜…ä¿®æ­£
from src.training.trainer import BiEncoderPairTrainer, MarginRankingTrainer, ContrastiveTrainer, MultipleNegativesRankingTrainer
from src.utils.optimization import create_optimizer_grouped_parameters

def compute_metrics(eval_pred):
    """
    Bi-Encoder (BCE Loss / Contrastive) ç”¨ã®è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
    Cross-Encoder (MarginRankingLoss) ã§ã¯é€šå¸¸metricsè¨ˆç®—ã¯é›£ã—ã„ã®ã§ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ãŒã€
    ä¾¿å®œä¸Šã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãªã„ã‚ˆã†ã«ã—ã¦ãŠãã€‚
    """
    predictions, labels = eval_pred
    
    # predictionsãŒã‚¿ãƒ—ãƒ«ã®å ´åˆ (Contrastive, MarginRankingãªã©)
    if isinstance(predictions, tuple):
        # MarginRankingTrainerã¯ (pos_score, neg_score) ã‚’è¿”ã™ã‚ˆã†å®Ÿè£…ã—ãŸå ´åˆ
        # ã“ã“ã§ã®ç²¾åº¦è¨ˆç®—ã¯å®šç¾©ãŒé›£ã—ã„ã®ã§ãƒ€ãƒŸãƒ¼ã‚’è¿”ã™ã‹ã€
        # Pos > Neg ã¨ãªã£ã¦ã„ã‚‹å‰²åˆï¼ˆAccuracyï¼‰ã‚’è¨ˆç®—ã™ã‚‹
        pos_scores = predictions[0] # (batch,)
        if len(predictions) > 1:
            neg_scores = predictions[1] # (batch,)
            # Pos > Neg ãªã‚‰æ­£è§£ (1), é€†ãªã‚‰ä¸æ­£è§£ (0)
            # numpyé…åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’æƒ³å®š
            acc = (pos_scores > neg_scores).mean()
            return {"accuracy": acc}
        else:
            return {}
            
    # é€šå¸¸ã®åˆ†é¡ (Logits)
    preds = (predictions > 0).astype(int).reshape(-1)
    if labels is not None:
        labels = labels.astype(int).reshape(-1)
        acc = accuracy_score(labels, preds)
        return {'accuracy': acc}
    
    return {}

@hydra.main(config_path="../configs", config_name="train", version_base=None)
def main(cfg: DictConfig):
    print(f"=== Starting Training: {cfg.model.type} ===")
    print(OmegaConf.to_yaml(cfg))
    
    if cfg.logging.use_wandb:
        wandb.init(
            project=cfg.logging.project_name,
            name=cfg.logging.run_name,
            tags=cfg.logging.tags,
            config=OmegaConf.to_container(cfg, resolve=True)
        )
    
    tokenizer = AutoTokenizer.from_pretrained(cfg.model.name)
    dataset_handler = TextRankingDataset(cfg, tokenizer)
    tokenized_datasets = dataset_handler.load_and_prepare()
    
    print(f"Loading model: {cfg.model.name}")
    model_config = AutoConfig.from_pretrained(cfg.model.name)
    
    # --- Trainerã¨ãƒ¢ãƒ‡ãƒ«ã®é¸æŠãƒ­ã‚¸ãƒƒã‚¯ ---
    compute_metrics_func = None

    if cfg.model.type == "cross_encoder":
        # Cross-Encoder (Reranker)
        model_config.num_labels = 1
        model = CrossEncoderMarginModel.from_pretrained(cfg.model.name, config=model_config)
        trainer_cls = MarginRankingTrainer
        # Cross-Encoderã§ã¯æ­£è§£ç‡(Pos > Negã®å‰²åˆ)ã‚’è¨ˆç®—ã•ã›ã‚‹ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã«è‰¯ã„
        compute_metrics_func = compute_metrics
        
    else: # bi_encoder
        head_type = cfg.model.get("head_type", "ranknet")
        loss_type = cfg.training.get("loss_type", "pair_score")
        
        print(f"Bi-Encoder Head: {head_type}, Loss: {loss_type}")
        
        model = SiameseBiEncoder.from_pretrained(
            cfg.model.name, 
            config=model_config, 
            head_type=head_type
        )
        
        adapter_name = cfg.model.get("adapter_name", None)
        if adapter_name:
            print(f"ğŸ”„ Loading Adapter: {adapter_name}")
            adapters.init(model.bert)
            try:
                loaded_name = model.bert.load_adapter(adapter_name, source="hf", set_active=True)
            except:
                loaded_name = model.bert.load_adapter(adapter_name, set_active=True)
            
            model.bert.set_active_adapters(loaded_name)
            print(f"âœ… Adapter '{loaded_name}' activated.")
            
            if cfg.model.get("freeze_base", False):
                print("â„ï¸  Freezing base model parameters (Training Adapter only)")
                for param in model.bert.parameters():
                    param.requires_grad = False
                for name, param in model.named_parameters():
                    if "adapter" in name or "classifier_head" in name:
                        param.requires_grad = True

        if loss_type == "mnrl":
            print("Using MultipleNegativesRankingTrainer")
            trainer_cls = MultipleNegativesRankingTrainer
        elif head_type == "none":
            print("Using ContrastiveTrainer")
            trainer_cls = ContrastiveTrainer
            compute_metrics_func = compute_metrics
        else:
            print("Using BiEncoderPairTrainer")
            trainer_cls = BiEncoderPairTrainer
            compute_metrics_func = compute_metrics

    # 4. ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ä½œæˆ
    base_lr = cfg.training.learning_rate
    head_lr = cfg.training.get("head_learning_rate", base_lr)
    
    optimizer_grouped_parameters = create_optimizer_grouped_parameters(
        model, base_lr, head_lr, cfg.training.weight_decay
    )
    optimizer = AdamW(optimizer_grouped_parameters)

    # 5. Arguments
    output_dir = cfg.training.output_dir
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    args = TrainingArguments(
        output_dir=output_dir,
        per_device_train_batch_size=cfg.training.batch_size,
        per_device_eval_batch_size=cfg.training.batch_size,
        num_train_epochs=cfg.training.epochs,
        learning_rate=base_lr, 
        weight_decay=cfg.training.weight_decay,
        warmup_ratio=cfg.training.warmup_ratio,
        logging_strategy="steps",
        logging_steps=cfg.training.logging_steps,
        eval_strategy="steps",
        eval_steps=cfg.training.eval_steps,
        save_strategy="steps",
        save_steps=cfg.training.save_steps,
        save_total_limit=cfg.training.save_total_limit,
        load_best_model_at_end=True,
        report_to="wandb" if cfg.logging.use_wandb else "none",
        run_name=cfg.logging.run_name, 
        remove_unused_columns=False,
        metric_for_best_model="loss", # MarginRankingLossã¯å°ã•ã„æ–¹ãŒè‰¯ã„
        greater_is_better=False,
        gradient_accumulation_steps=cfg.training.get("gradient_accumulation_steps", 1)
    )
    
    callbacks = []
    if cfg.training.get("patience"):
        print(f"Early stopping enabled with patience: {cfg.training.patience}")
        callbacks.append(EarlyStoppingCallback(early_stopping_patience=cfg.training.patience))
        
    # â˜…è¿½åŠ : ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®æº–å‚™
    data_collator = None
    if cfg.model.type == "cross_encoder":
        print("Using CrossEncoderTripletCollator")
        data_collator = CrossEncoderTripletCollator(tokenizer)

    # 6. TraineråˆæœŸåŒ–
    trainer_kwargs = {
        "model": model,
        "args": args,
        "train_dataset": tokenized_datasets["train"],
        "eval_dataset": tokenized_datasets["validation"],
        "tokenizer": tokenizer,
        "optimizers": (optimizer, None),
        "compute_metrics": compute_metrics_func,
        "callbacks": callbacks,
        "data_collator": data_collator # â˜…è¿½åŠ 
    }

    if trainer_cls == MultipleNegativesRankingTrainer:
        trainer_kwargs["scale"] = cfg.training.get("scale", 20.0)
    elif trainer_cls in [ContrastiveTrainer, MarginRankingTrainer]:
        trainer_kwargs["margin"] = cfg.training.margin
    
    trainer = trainer_cls(**trainer_kwargs)
    
    print("Starting training...")
    trainer.train()
    
    best_model_path = os.path.join(output_dir, "best_model")
    print(f"Saving best model to {best_model_path}")
    trainer.save_model(best_model_path)
    
    if cfg.logging.use_wandb:
        wandb.finish()

if __name__ == "__main__":
    main()